{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2045730-283d-49a9-b8ce-8665a0046be7",
   "metadata": {},
   "source": [
    "# Machine Learning Analysis\n",
    "\n",
    "### This notebook will analyze and classify the encoded data to predict which passengers would be transported using random forest and gradient boosting classifier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed921a9-3e28-476a-8b4e-54e9bc272047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First start by importing the relevant packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc02ac-2184-46a1-81a0-b83d85dd73c2",
   "metadata": {},
   "source": [
    "#### Random forest classifier: 1<sup>st</sup> iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337a42d9-9138-4c4e-937f-1378ae86ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data (stored locally)\n",
    "train_RF_iter1 = pd.read_csv('train_logic_impute.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83b82c6-7c51-4a51-b2db-02b36deda66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the features and response (Transported)\n",
    "X_RF_iter1 = train_RF_iter1.drop(columns = 'Transported')\n",
    "y_RF_iter1 = train_RF_iter1.Transported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c98cf3c3-ca3c-4e74-ae85-b31299c163c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now further subdivide the data into training and validation sets\n",
    "X_RF_iter1_train, X_RF_iter1_validate, y_RF_iter1_train, y_RF_iter1_validate = train_test_split(X_RF_iter1,\n",
    "                                                                                                y_RF_iter1,\n",
    "                                                                                                test_size = 0.2,\n",
    "                                                                                                random_state = 17,\n",
    "                                                                                                shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ac248e-9d2d-4f62-885b-327653658362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to make an initial estimate of how many trees are needed in the forest\n",
    "def n_estimator_eval():\n",
    "    n_estimators_list = [10,25,50,75,100,150,200,250,300,350,400,450,500,550,600,700]\n",
    "    for n_estimators_eval in n_estimators_list:\n",
    "        model_RF_eval = RandomForestClassifier(n_estimators = n_estimators_eval, random_state = 17, n_jobs = -1)\n",
    "        model_RF_eval.fit(X_RF_iter1_train, y_RF_iter1_train)\n",
    "        y_RF_eval_valid_predict = model_RF_eval.predict(X_RF_iter1_validate)\n",
    "        acc_score_eval = accuracy_score(y_RF_iter1_validate, y_RF_eval_valid_predict) # (# of correct predictions)/(total # of predictions)\n",
    "        acc_score_eval_rounded = round(acc_score_eval, ndigits = 4)\n",
    "        print(f'With {n_estimators_eval} trees, the validation accuracy score was {acc_score_eval_rounded}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "026625af-8382-4ff8-a055-da988f71e9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 10 trees, the validation accuracy score was 0.7861\n",
      "With 25 trees, the validation accuracy score was 0.793\n",
      "With 50 trees, the validation accuracy score was 0.8045\n",
      "With 75 trees, the validation accuracy score was 0.8091\n",
      "With 100 trees, the validation accuracy score was 0.8068\n",
      "With 150 trees, the validation accuracy score was 0.8062\n",
      "With 200 trees, the validation accuracy score was 0.8114\n",
      "With 250 trees, the validation accuracy score was 0.8108\n",
      "With 300 trees, the validation accuracy score was 0.8074\n",
      "With 350 trees, the validation accuracy score was 0.8062\n",
      "With 400 trees, the validation accuracy score was 0.8051\n",
      "With 450 trees, the validation accuracy score was 0.8091\n",
      "With 500 trees, the validation accuracy score was 0.8062\n",
      "With 550 trees, the validation accuracy score was 0.8068\n",
      "With 600 trees, the validation accuracy score was 0.8085\n",
      "With 700 trees, the validation accuracy score was 0.8062\n"
     ]
    }
   ],
   "source": [
    "# Now call the function and observe the results\n",
    "n_estimator_eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3129a5-505d-4670-9cc6-9eeb90357450",
   "metadata": {},
   "source": [
    "The validation set accuracy is greatest with 200 trees (for the default random forest parameters), so use this for the first iteration of the fitting (although this does seem a little low)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "504fef6b-76da-48f7-b13e-11ad40cb7222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation set accuracy score is: 0.8114\n"
     ]
    }
   ],
   "source": [
    "# Fit model with only n_estimators & random_state specified\n",
    "model_RF_iter1 = RandomForestClassifier(n_estimators = 200, random_state = 17, n_jobs = -1)\n",
    "model_RF_iter1.fit(X_RF_iter1_train, y_RF_iter1_train)\n",
    "y_RF_valid_predict = model_RF_iter1.predict(X_RF_iter1_validate)\n",
    "acc_score_iter1 = accuracy_score(y_RF_iter1_validate, y_RF_valid_predict)\n",
    "print('The validation set accuracy score is:',round(acc_score_iter1, ndigits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e48e9f46-5269-4d46-b8df-db0ad31f2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also load the test set and use the fitted model to predict the response\n",
    "test_RF_iter1 = pd.read_csv('test_logic_impute.csv')\n",
    "test_RF_iter1_predict = model_RF_iter1.predict(test_RF_iter1.drop(columns = 'PassengerId'))\n",
    "test_RF_iter1_predict_S = pd.Series(test_RF_iter1_predict)\n",
    "# Save the predictions in a .csv file for submission to evaluate the accuracy of the fit\n",
    "# RF_iter1_submission_dict = {'PassengerId':test_RF_iter1.PassengerId,'Transported':test_RF_iter1_predict_S}\n",
    "# RF_iter1_submission_df = pd.DataFrame(data = RF_iter1_submission_dict)\n",
    "# RF_iter1_submission_df.to_csv(path_or_buf = 'Random_Forest_Classifier_Iteration_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25b8e31-eebd-4b93-8ad6-8438088bdc1a",
   "metadata": {},
   "source": [
    "#### Random forest classifier: 2<sup>nd</sup> iteration\n",
    "\n",
    "Now perform hyperparamter tuning to improve the model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b3e54f-b62b-42b3-9f47-95ad640738d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data (stored locally)\n",
    "train_RF_iter2 = pd.read_csv('train_logic_impute.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34262840-92ef-4083-8235-1847f073b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the features and response (Transported)\n",
    "X_RF_iter2 = train_RF_iter2.drop(columns = 'Transported')\n",
    "y_RF_iter2 = train_RF_iter2.Transported"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657ad70-6e70-444c-8fee-19bcbc68c447",
   "metadata": {},
   "source": [
    "While the initial fitting was done with 200 trees, this feels a little low. There was a another local maximum at 450 trees, which seems more reasonable, so use this for hyperparameter grid search tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17d3dbbe-13a6-4e3a-926f-686bb5cb7616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifier model\n",
    "random_forest_class = RandomForestClassifier(n_estimators = 450, random_state = 17, n_jobs = -1)\n",
    "# Set conditions for the grid parameter search\n",
    "# Initial conditions used were:\n",
    "# p_grid = {'max_depth':np.linspace(5,30,6).astype(int),'max_features':np.linspace(2,18,5).astype(int)}\n",
    "p_grid = {'max_depth':np.linspace(6,14,5).astype(int),'max_features':np.linspace(3,9,7).astype(int)}\n",
    "cross_val_set = KFold(n_splits = 5, shuffle = True, random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8a9790b-3b71-47c7-9438-7fb6b69a1b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator = random_forest_class, param_grid = p_grid, scoring = 'accuracy', n_jobs = -1, cv = cross_val_set)\n",
    "grid_search.fit(X_RF_iter2, y_RF_iter2)\n",
    "# Store results in a dataframe\n",
    "grid_results = pd.DataFrame(grid_search.cv_results_).sort_values(by = 'rank_test_score', ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c18dc34-7bd1-444f-9e39-7e61f22f7c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal parameters were:\n",
      "max_depth = 10\n",
      "max_features = 6\n",
      "The mean validation k-fold accuracy was: 0.8026\n"
     ]
    }
   ],
   "source": [
    "# Extract and print key results from dataframe\n",
    "grid_max_depth = grid_results.loc[0, 'param_max_depth']\n",
    "grid_max_features = grid_results.loc[0,'param_max_features']\n",
    "test_acc = grid_results.loc[0,'mean_test_score']\n",
    "\n",
    "print('The optimal parameters were:')\n",
    "print('max_depth =',grid_max_depth)\n",
    "print('max_features =',grid_max_features)\n",
    "print('The mean validation k-fold accuracy was:',round(test_acc, ndigits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb96c3a1-a8db-4a26-83c9-e7be8c093fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, max_features=6, n_estimators=450,\n",
       "                       random_state=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, max_features=6, n_estimators=450,\n",
       "                       random_state=17)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, max_features=6, n_estimators=450,\n",
       "                       random_state=17)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now fit the model using the optimal parameters\n",
    "model_RF_iter2 = RandomForestClassifier(n_estimators = 450,\n",
    "                                        max_depth = grid_max_depth,\n",
    "                                        max_features = grid_max_features,\n",
    "                                        random_state = 17)\n",
    "model_RF_iter2.fit(X_RF_iter2, y_RF_iter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "886b6b9f-f70b-4d78-b57f-5f23fb642597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test set and use the fitted model to predict the response\n",
    "test_RF_iter2 = pd.read_csv('test_logic_impute.csv')\n",
    "test_RF_iter2_predict = model_RF_iter2.predict(test_RF_iter2.drop(columns = 'PassengerId'))\n",
    "test_RF_iter2_predict_S = pd.Series(test_RF_iter2_predict)\n",
    "# Save the predictions in a .csv file for submission to evaluate the accuracy of the fit\n",
    "# RF_iter2_submission_dict = {'PassengerId':test_RF_iter2.PassengerId,'Transported':test_RF_iter2_predict_S}\n",
    "# RF_iter2_submission_df = pd.DataFrame(data = RF_iter2_submission_dict)\n",
    "# RF_iter2_submission_df.to_csv(path_or_buf = 'Random_Forest_Classifier_Iteration_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d24ad4-ff8e-46e1-b6f8-faf4d722f71f",
   "metadata": {},
   "source": [
    "#### Gradient boosting classifier: 1<sup>st</sup> iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b53886d4-6269-4bdd-9e18-1ee3cf396753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data (stored locally)\n",
    "train_GBC_iter1 = pd.read_csv('train_logic_impute.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2347f06d-fb4e-4f56-9a32-5ff8294c561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the features and response (Transported)\n",
    "X_GBC_iter1 = train_GBC_iter1.drop(columns = 'Transported')\n",
    "y_GBC_iter1 = train_GBC_iter1.Transported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c335ede8-2d69-4014-81cd-f17ea656c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now further subdivide the data into training and validation sets\n",
    "X_GBC_iter1_train, X_GBC_iter1_validate, y_GBC_iter1_train, y_GBC_iter1_validate = train_test_split(X_GBC_iter1,\n",
    "                                                                                                    y_GBC_iter1,\n",
    "                                                                                                    test_size = 0.2,\n",
    "                                                                                                    random_state = 17,\n",
    "                                                                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1512e3db-8715-4e2e-a6c1-3dcd6f9c3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to make an initial estimate of how many boosts are optimal\n",
    "def n_estimator_eval():\n",
    "    n_estimators_list = [10,25,50,75,100,150,175,200,225,250,300,350,400,450,500,550,600]\n",
    "    for n_estimators_eval in n_estimators_list:\n",
    "        model_GBC_eval = GradientBoostingClassifier(n_estimators = n_estimators_eval, random_state = 17)\n",
    "        model_GBC_eval.fit(X_GBC_iter1_train, y_GBC_iter1_train)\n",
    "        y_GBC_eval_valid_predict = model_GBC_eval.predict(X_GBC_iter1_validate)\n",
    "        acc_score_eval = accuracy_score(y_GBC_iter1_validate, y_GBC_eval_valid_predict) # (# of correct predictions)/(total # of predictions)\n",
    "        acc_score_eval_rounded = round(acc_score_eval, ndigits = 4)\n",
    "        print(f'With {n_estimators_eval} boosting stages, the validation accuracy score was {acc_score_eval_rounded}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efab421e-7bbb-4adb-b54c-bf5b4bd40878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 10 boosting stages, the validation accuracy score was 0.7706\n",
      "With 25 boosting stages, the validation accuracy score was 0.8039\n",
      "With 50 boosting stages, the validation accuracy score was 0.8074\n",
      "With 75 boosting stages, the validation accuracy score was 0.8114\n",
      "With 100 boosting stages, the validation accuracy score was 0.8108\n",
      "With 150 boosting stages, the validation accuracy score was 0.8131\n",
      "With 175 boosting stages, the validation accuracy score was 0.8125\n",
      "With 200 boosting stages, the validation accuracy score was 0.812\n",
      "With 225 boosting stages, the validation accuracy score was 0.8125\n",
      "With 250 boosting stages, the validation accuracy score was 0.812\n",
      "With 300 boosting stages, the validation accuracy score was 0.8125\n",
      "With 350 boosting stages, the validation accuracy score was 0.8137\n",
      "With 400 boosting stages, the validation accuracy score was 0.8125\n",
      "With 450 boosting stages, the validation accuracy score was 0.8154\n",
      "With 500 boosting stages, the validation accuracy score was 0.8148\n",
      "With 550 boosting stages, the validation accuracy score was 0.8154\n",
      "With 600 boosting stages, the validation accuracy score was 0.8154\n"
     ]
    }
   ],
   "source": [
    "n_estimator_eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6e267b-5ff3-4874-8d5a-8bc786c6b1c2",
   "metadata": {},
   "source": [
    "The validation accuracy is greatest with 450 boosts, so use this amount for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4461588c-3182-4542-ae90-46991b8a0590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation set accuracy score is: 0.8154\n"
     ]
    }
   ],
   "source": [
    "# Fit model with only n_estimators & random_state specified\n",
    "model_GBC_iter1 = GradientBoostingClassifier(n_estimators = 450, random_state = 17)\n",
    "model_GBC_iter1.fit(X_GBC_iter1_train, y_GBC_iter1_train)\n",
    "y_GBC_valid_predict = model_GBC_iter1.predict(X_GBC_iter1_validate)\n",
    "acc_score_iter1 = accuracy_score(y_GBC_iter1_validate, y_GBC_valid_predict)\n",
    "print('The validation set accuracy score is:',round(acc_score_iter1, ndigits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c82e7737-2af0-412a-ba79-40d38bfc52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test set and use the fitted model to predict the response\n",
    "test_GBC_iter1 = pd.read_csv('test_logic_impute.csv')\n",
    "test_GBC_iter1_predict = model_GBC_iter1.predict(test_GBC_iter1.drop(columns = 'PassengerId'))\n",
    "test_GBC_iter1_predict_S = pd.Series(test_GBC_iter1_predict)\n",
    "# Save the predictions in a .csv file for submission to evaluate the accuracy of the fit\n",
    "# GBC_iter1_submission_dict = {'PassengerId':test_GBC_iter1.PassengerId,'Transported':test_GBC_iter1_predict_S}\n",
    "# GBC_iter1_submission_df = pd.DataFrame(data = GBC_iter1_submission_dict)\n",
    "# GBC_iter1_submission_df.to_csv(path_or_buf = 'Gradient_Boosting_Classifier_Iteration_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937431a6-a9ef-4006-b4a6-031194033806",
   "metadata": {},
   "source": [
    "#### Gradient boosting classifier: 2<sup>nd</sup> iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79720ef3-6105-4af2-82bf-a2c7f75314fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data (stored locally)\n",
    "train_GBC_iter2 = pd.read_csv('train_logic_impute.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb1b9bc8-248e-4566-887c-60536c5ea54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the features and response (Transported)\n",
    "X_GBC_iter2 = train_GBC_iter2.drop(columns = 'Transported')\n",
    "y_GBC_iter2 = train_GBC_iter2.Transported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28dd16d1-ab07-44b4-8e46-319c02746028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifier model\n",
    "grad_boost_class = GradientBoostingClassifier(random_state = 17)\n",
    "# Set conditions for the grid parameter search\n",
    "# Initial conditions used were:\n",
    "# p_grid = {'n_estimators':np.linspace(100,500,9).astype(int),\n",
    "#           'max_depth':np.linspace(1,8,8).astype(int),\n",
    "#           'max_features':np.linspace(2,18,9).astype(int)}\n",
    "p_grid = {'n_estimators':np.linspace(50,150,5).astype(int),\n",
    "          'max_depth':np.linspace(5,8,4).astype(int),\n",
    "          'max_features':np.linspace(1,6,6).astype(int)}\n",
    "cross_val_set = KFold(n_splits = 5, shuffle = True, random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82937735-0671-4cbe-811e-4b0073486bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator = grad_boost_class, param_grid = p_grid, scoring = 'accuracy', n_jobs = -1, cv = cross_val_set)\n",
    "grid_search.fit(X_GBC_iter2, y_GBC_iter2)\n",
    "# Store results in a dataframe\n",
    "grid_results = pd.DataFrame(grid_search.cv_results_).sort_values(by = 'rank_test_score', ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcc1d020-b30e-46af-b3b1-82cfc42f22f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal parameters were:\n",
      "n_estimators = 100\n",
      "max_depth = 6\n",
      "max_features = 2\n",
      "The mean validation k-fold accuracy was: 0.8048\n"
     ]
    }
   ],
   "source": [
    "# Extract and print key results from dataframe\n",
    "grid_n_estimators = grid_results.loc[0, 'param_n_estimators']\n",
    "grid_max_depth = grid_results.loc[0, 'param_max_depth']\n",
    "grid_max_features = grid_results.loc[0,'param_max_features']\n",
    "test_acc = grid_results.loc[0,'mean_test_score']\n",
    "\n",
    "print('The optimal parameters were:')\n",
    "print('n_estimators =',grid_n_estimators)\n",
    "print('max_depth =',grid_max_depth)\n",
    "print('max_features =',grid_max_features)\n",
    "print('The mean validation k-fold accuracy was:',round(test_acc, ndigits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ff03c0d-d776-4351-ba9c-939b9f815141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(max_depth=6, max_features=2, random_state=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=6, max_features=2, random_state=17)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(max_depth=6, max_features=2, random_state=17)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now fit the model using the optimal parameters\n",
    "model_GBC_iter2 = GradientBoostingClassifier(n_estimators = grid_n_estimators,\n",
    "                                             max_depth = grid_max_depth,\n",
    "                                             max_features = grid_max_features,\n",
    "                                             random_state = 17)\n",
    "model_GBC_iter2.fit(X_GBC_iter2, y_GBC_iter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b915a955-0e1f-4f7d-b467-085f14b4395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test set and use the fitted model to predict the response\n",
    "test_GBC_iter2 = pd.read_csv('test_logic_impute.csv')\n",
    "test_GBC_iter2_predict = model_GBC_iter2.predict(test_GBC_iter2.drop(columns = 'PassengerId'))\n",
    "test_GBC_iter2_predict_S = pd.Series(test_GBC_iter2_predict)\n",
    "# Save the predictions in a .csv file for submission to evaluate the accuracy of the fit\n",
    "# GBC_iter2_submission_dict = {'PassengerId':test_GBC_iter2.PassengerId,'Transported':test_GBC_iter2_predict_S}\n",
    "# GBC_iter2_submission_df = pd.DataFrame(data = GBC_iter2_submission_dict)\n",
    "# GBC_iter2_submission_df.to_csv(path_or_buf = 'Gradient_Boosting_Classifier_Iteration_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39affd8b-9d42-48cd-a146-f9e5f976c17a",
   "metadata": {},
   "source": [
    "#### Summary of machine learning analysis results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3d4af-d921-4aa8-bd93-615f9264c829",
   "metadata": {},
   "source": [
    "| Model | Validation Set Accuracy Score | Test Set Accuracy Score |\n",
    "| --- | -: | -: |\n",
    "| Random forest classifier 1<sup>st</sup> iteration | 0.8114 | 0.7861 |\n",
    "| Random forest classifier 2<sup>nd</sup> iteration | 0.8026 | 0.7942 |\n",
    "| Gradient boosting classifier 1<sup>st</sup> iteration | 0.8154 | 0.7912 |\n",
    "| Gradient boosting classifier 2<sup>nd</sup> iteration | 0.8048 | 0.7933 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa17105-d8e2-40f0-9d98-cebfee63e130",
   "metadata": {},
   "source": [
    "The test set accuracy scores are obtained from submitting predicted values for whether the passenger was transported in the test set to compare with the actual true results on Kaggle.\n",
    "\n",
    "The test scores are all slightly lower than the validation scores, but the difference is still relatively small. Overall, the random forest classifier after hyperparameter tuning was the most accurate method. Both the random forest and gradient boosting classifiers had lower validation set accuracy scores after hyperparameter tuning (the test set accuracy improved in both cases). This may be due to (slight) model overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
